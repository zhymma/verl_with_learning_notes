# SFT è®­ç»ƒ (Supervised Fine-Tuning)

> ç›‘ç£å¾®è°ƒ - RL è®­ç»ƒçš„å‰ç½®æ­¥éª¤

---

## ğŸ“‹ æ¦‚è¿°

**SFT (Supervised Fine-Tuning)** æ˜¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„é‡è¦å‰ç½®æ­¥éª¤ã€‚é€šè¿‡åœ¨é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ä¸Šè¿›è¡Œç›‘ç£å­¦ä¹ ï¼Œå¯ä»¥ä¸ºåç»­çš„ RL è®­ç»ƒæä¾›æ›´å¥½çš„åˆå§‹åŒ–ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ SFTï¼Ÿ

- âœ… **æ›´å¥½çš„åˆå§‹åŒ–**ï¼šRL ä» SFT æ¨¡å‹å¼€å§‹ï¼Œæ”¶æ•›æ›´å¿«
- âœ… **æ•°æ®æ ¼å¼é€‚åº”**ï¼šè®©æ¨¡å‹ç†Ÿæ‚‰ç‰¹å®šçš„æ•°æ®æ ¼å¼
- âœ… **åŸºç¡€èƒ½åŠ›å»ºç«‹**ï¼šåœ¨ RL ä¹‹å‰å»ºç«‹åŸºæœ¬çš„ä»»åŠ¡èƒ½åŠ›
- âœ… **å‡å°‘æ¢ç´¢æˆæœ¬**ï¼šç¼©å° RL çš„æœç´¢ç©ºé—´

### SFT â†’ RL çš„å®Œæ•´æµç¨‹

```
1. é¢„è®­ç»ƒæ¨¡å‹
   â†“
2. SFT è®­ç»ƒï¼ˆæœ¬ç›®å½•ï¼‰
   â”œâ”€ åœ¨é«˜è´¨é‡æ•°æ®ä¸Šç›‘ç£å­¦ä¹ 
   â”œâ”€ å­¦ä¹ ä»»åŠ¡ç‰¹å®šæ ¼å¼
   â””â”€ å»ºç«‹åŸºç¡€èƒ½åŠ›
   â†“
3. RL è®­ç»ƒ
   â”œâ”€ ä» SFT checkpoint å¼€å§‹
   â”œâ”€ é€šè¿‡å¥–åŠ±ä¿¡å·ä¼˜åŒ–
   â””â”€ è·å¾—æ›´å¥½çš„æ€§èƒ½
```

### é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ˜¯å¦éœ€è¦ SFT | è¯´æ˜ |
|------|-------------|------|
| **æ•°å­¦æ¨ç†** | â­â­â­â­â­ å¼ºçƒˆæ¨è | SFT å»ºç«‹æ¨ç†æ¨¡å¼ |
| **ä»£ç ç”Ÿæˆ** | â­â­â­â­â­ å¼ºçƒˆæ¨è | SFT å­¦ä¹ ä»£ç è¯­æ³• |
| **å·¥å…·è°ƒç”¨** | â­â­â­â­â­ å¿…éœ€ | SFT å­¦ä¹ å·¥å…·æ ¼å¼ |
| **å¯¹è¯è´¨é‡** | â­â­â­â­ æ¨è | SFT å»ºç«‹å¯¹è¯æ¨¡å¼ |
| **é€šç”¨ RLHF** | â­â­â­ å¯é€‰ | é¢„è®­ç»ƒæ¨¡å‹å·²ç»å¾ˆå¥½ |

---

## ğŸ”§ å‰ç½®æ¡ä»¶

### ç¡¬ä»¶è¦æ±‚

```
æœ€ä½é…ç½®ï¼š
- GPU: 1 å¼  24GB GPUï¼ˆå¦‚ RTX 3090ï¼‰
- å†…å­˜: 32GB
- å­˜å‚¨: 50GB

æ¨èé…ç½®ï¼š
- GPU: 4-8 å¼  40GB GPUï¼ˆå¦‚ A100ï¼‰
- å†…å­˜: 128GB+
- å­˜å‚¨: 200GB+
```

### è½¯ä»¶ä¾èµ–

```bash
# å®‰è£… verl
pip install -e .[test]

# éªŒè¯å®‰è£…
python -c "import verl; print(verl.__version__)"
```

### æ•°æ®å‡†å¤‡

SFT éœ€è¦é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼š

#### 1. GSM8K SFT æ•°æ®

```bash
# å¤„ç† GSM8K SFT æ•°æ®ï¼ˆåŒ…å«å®Œæ•´è§£é¢˜è¿‡ç¨‹ï¼‰
python examples/data_preprocess/gsm8k_multiturn_sft.py \
    --local_save_dir ~/data/gsm8k_sft

# æ•°æ®æ ¼å¼ï¼š
# {
#   "prompt": [{"role": "user", "content": "Question..."}],
#   "response": "Step 1: ... Step 2: ... #### 42",  # å®Œæ•´çš„è§£é¢˜è¿‡ç¨‹
#   "data_source": "gsm8k_sft"
# }
```

#### 2. å¤šè½®å¯¹è¯ SFT æ•°æ®

```bash
# å¤„ç†å¤šè½®å¯¹è¯æ•°æ®
python examples/data_preprocess/multiturn.py \
    --local_save_dir ~/data/multiturn_sft

# æ•°æ®æ ¼å¼ï¼ˆå¤šè½®ï¼‰ï¼š
# {
#   "prompt": [
#     {"role": "user", "content": "Q1"},
#     {"role": "assistant", "content": "A1"},
#     {"role": "user", "content": "Q2"}
#   ],
#   "response": "A2",
#   "data_source": "multiturn_sft"
# }
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¤ºä¾‹ 1ï¼šQwen2.5-0.5B SFTï¼ˆæœ€ç®€å•ï¼‰

```bash
# GSM8K SFT è®­ç»ƒ
cd examples/sft/gsm8k

bash run_qwen_05_sp2.sh

# é¢„æœŸè¾“å‡ºï¼š
# Epoch 0: loss=2.134
# Epoch 1: loss=1.567
# Epoch 2: loss=1.234
# ...
# Epoch 9: loss=0.567
# âœ… SFT è®­ç»ƒå®Œæˆï¼
# æ¨¡å‹ä¿å­˜åˆ°: ./checkpoints/qwen0.5b_sft/
```

### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ LoRAï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰

```bash
# LoRA SFT è®­ç»ƒï¼ˆæ˜¾å­˜å ç”¨æ›´å°‘ï¼‰
bash run_qwen_05_peft.sh

# LoRA é…ç½®ï¼š
# - r=16ï¼ˆrankï¼‰
# - alpha=32
# - target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
#
# æ˜¾å­˜å ç”¨ï¼š~12GBï¼ˆç›¸æ¯”å…¨é‡çš„ ~20GBï¼‰
```

### ç¤ºä¾‹ 3ï¼šGemma 2B SFT

```bash
# Gemma æ¨¡å‹ SFT
bash examples/sft/gsm8k/run_gemma_2b.sh

# æˆ–è‡ªå®šä¹‰é…ç½®
python3 -m verl.trainer.fsdp_sft_trainer \
    data.train_files=$HOME/data/gsm8k_sft/train.parquet \
    data.val_files=$HOME/data/gsm8k_sft/test.parquet \
    model.path=google/gemma-2-2b-it \
    trainer.default_local_dir=./checkpoints/gemma2b_sft \
    trainer.n_gpus_per_node=2 \
    trainer.total_epochs=10
```

### ç¤ºä¾‹ 4ï¼šå¤šæ¨¡æ€ VLM SFT

```bash
# å¤šæ¨¡æ€ SFTï¼ˆå›¾åƒ + æ–‡æœ¬ï¼‰
cd examples/sft/vlm

python run_vlm_sft.py \
    --model_path Qwen/Qwen2.5-VL-7B-Instruct \
    --data_path ~/data/vlm_sft/train.parquet \
    --output_dir ./checkpoints/qwen2.5_vl_sft
```

---

## ğŸ“– è¯¦ç»†é…ç½®

### SFT è®­ç»ƒé…ç½®

#### 1. æ•°æ®é…ç½®

```yaml
data:
  train_files: ~/data/gsm8k_sft/train.parquet
  val_files: ~/data/gsm8k_sft/test.parquet
  train_batch_size: 128              # æ‰¹æ¬¡å¤§å°
  max_prompt_length: 1024            # æœ€å¤§ prompt é•¿åº¦
  max_response_length: 512           # æœ€å¤§ response é•¿åº¦
  num_workers: 4                     # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
```

#### 2. æ¨¡å‹é…ç½®

```yaml
model:
  path: Qwen/Qwen2.5-7B-Instruct     # æ¨¡å‹è·¯å¾„

  # FSDP é…ç½®
  fsdp_config:
    param_offload: False             # å‚æ•°å¸è½½åˆ° CPU
    optimizer_offload: False         # ä¼˜åŒ–å™¨å¸è½½
    gradient_checkpointing: True     # æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆçœæ˜¾å­˜ï¼‰

  # LoRA é…ç½®ï¼ˆå¯é€‰ï¼‰
  peft_config:
    enable: True                     # å¯ç”¨ LoRA
    r: 16                            # LoRA rank
    alpha: 32                        # LoRA alpha
    target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
    lora_dropout: 0.05
```

#### 3. ä¼˜åŒ–å™¨é…ç½®

```yaml
optim:
  lr: 5e-6                           # å­¦ä¹ ç‡ï¼ˆSFT é€šå¸¸æ¯” RL å°ï¼‰
  weight_decay: 0.01                 # æƒé‡è¡°å‡
  warmup_steps: 100                  # Warmup æ­¥æ•°
  lr_scheduler: cosine               # å­¦ä¹ ç‡è°ƒåº¦å™¨
```

#### 4. è®­ç»ƒé…ç½®

```yaml
trainer:
  n_gpus_per_node: 4                 # æ¯èŠ‚ç‚¹ GPU æ•°
  nnodes: 1                          # èŠ‚ç‚¹æ•°
  total_epochs: 10                   # æ€»è½®æ•°
  save_freq: 2                       # ä¿å­˜é¢‘ç‡
  eval_freq: 1                       # è¯„ä¼°é¢‘ç‡
  default_local_dir: ./checkpoints   # ä¿å­˜ç›®å½•
  gradient_accumulation_steps: 1     # æ¢¯åº¦ç´¯ç§¯
  max_grad_norm: 1.0                 # æ¢¯åº¦è£å‰ª
```

---

## ğŸ’¡ è¿è¡Œç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šæ ‡å‡† SFT è®­ç»ƒæµç¨‹

```bash
# ç¬¬ 1 æ­¥ï¼šå‡†å¤‡æ•°æ®
python examples/data_preprocess/gsm8k_multiturn_sft.py \
    --local_save_dir ~/data/gsm8k_sft

# ç¬¬ 2 æ­¥ï¼šSFT è®­ç»ƒ
python3 -m verl.trainer.fsdp_sft_trainer \
    data.train_files=$HOME/data/gsm8k_sft/train.parquet \
    data.val_files=$HOME/data/gsm8k_sft/test.parquet \
    data.train_batch_size=128 \
    model.path=Qwen/Qwen2.5-7B-Instruct \
    optim.lr=5e-6 \
    trainer.n_gpus_per_node=4 \
    trainer.total_epochs=10 \
    trainer.default_local_dir=./checkpoints/qwen7b_sft

# ç¬¬ 3 æ­¥ï¼šè¯„ä¼° SFT æ¨¡å‹
python evaluate_sft.py \
    --model_path ./checkpoints/qwen7b_sft \
    --test_file ~/data/gsm8k/test.parquet

# ç¬¬ 4 æ­¥ï¼šä½¿ç”¨ SFT æ¨¡å‹è¿›è¡Œ RL è®­ç»ƒ
python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=grpo \
    actor_rollout_ref.model.path=./checkpoints/qwen7b_sft \
    data.train_files=$HOME/data/gsm8k/train.parquet \
    # ... å…¶ä»– RL å‚æ•° ...
```

### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ Liger Kernel åŠ é€Ÿ

```bash
# Liger Kernel å¯ä»¥åŠ é€Ÿè®­ç»ƒå¹¶å‡å°‘æ˜¾å­˜
bash examples/sft/gsm8k/run_qwen_05_sp2_liger.sh

# Liger ç‰¹ç‚¹ï¼š
# âœ… æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼ˆ~20% æå‡ï¼‰
# âœ… æ›´å°‘çš„æ˜¾å­˜å ç”¨ï¼ˆ~15% å‡å°‘ï¼‰
# âœ… æ•°å€¼ç¨³å®šæ€§æ›´å¥½
```

### ç¤ºä¾‹ 3ï¼šNPU è®­ç»ƒï¼ˆåä¸º Ascendï¼‰

```bash
# åœ¨åä¸º Ascend NPU ä¸Šè®­ç»ƒ
bash examples/sft/gsm8k/run_qwen3_8b_sft_peft_sp2_npu.sh

# NPU é…ç½®ï¼š
# - éœ€è¦å®‰è£… torch_npu
# - æ”¯æŒ FSDP å’Œ LoRA
# - æ€§èƒ½ä¸ A100 ç›¸å½“
```

### ç¤ºä¾‹ 4ï¼šè¶…å¤§æ¨¡å‹ SFTï¼ˆ36B+ï¼‰

```bash
# SEED-OSS 36B SFT
bash examples/sft/gsm8k/run_seed_oss_36b_sft.sh

# é…ç½®ï¼š
# - 8 å¼  80GB GPU
# - FSDP + æ··åˆç²¾åº¦
# - æ¢¯åº¦æ£€æŸ¥ç‚¹
# - é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š~4 å°æ—¶
```

---

## ğŸ¯ SFT æœ€ä½³å®è·µ

### 1. å­¦ä¹ ç‡é€‰æ‹©

```yaml
# SFT å­¦ä¹ ç‡é€šå¸¸æ¯”é¢„è®­ç»ƒå°ï¼Œæ¯” RL å°
å°æ¨¡å‹ï¼ˆ<7Bï¼‰:
  lr: 1e-5 åˆ° 5e-5

ä¸­ç­‰æ¨¡å‹ï¼ˆ7B-70Bï¼‰:
  lr: 5e-6 åˆ° 1e-5

å¤§æ¨¡å‹ï¼ˆ>70Bï¼‰:
  lr: 1e-6 åˆ° 5e-6

# æ¨èä½¿ç”¨ warmup
warmup_steps: æ€»æ­¥æ•°çš„ 5-10%
```

### 2. è®­ç»ƒè½®æ•°

```yaml
# SFT ä¸éœ€è¦å¤ªå¤šè½®æ¬¡
æ ‡å‡†ä»»åŠ¡: 5-10 epochs
ç®€å•ä»»åŠ¡: 3-5 epochs
å¤æ‚ä»»åŠ¡: 10-15 epochs

# æ³¨æ„è¿‡æ‹Ÿåˆï¼
# ä½¿ç”¨éªŒè¯é›†ç›‘æ§ï¼Œloss ä¸å†ä¸‹é™æ—¶åœæ­¢
```

### 3. Batch Size é€‰æ‹©

```yaml
# æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´
24GB GPUï¼ˆå•å¡ï¼‰:
  batch_size: 8-16ï¼ˆå…¨é‡ï¼‰
  batch_size: 32-64ï¼ˆLoRAï¼‰

40GB GPUï¼ˆå•å¡ï¼‰:
  batch_size: 16-32ï¼ˆå…¨é‡ï¼‰
  batch_size: 64-128ï¼ˆLoRAï¼‰

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å¢å¤§æœ‰æ•ˆ batch size
gradient_accumulation_steps: 4
# æœ‰æ•ˆ batch_size = batch_size Ã— accumulation_steps
```

### 4. æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡

```yaml
# å®å¯å°‘è€Œç²¾ï¼Œä¸è¦å¤šè€Œæ‚
é«˜è´¨é‡æ•°æ®ï¼ˆ1000 æ¡ï¼‰> ä½è´¨é‡æ•°æ®ï¼ˆ10000 æ¡ï¼‰

# æ•°æ®æ¸…æ´—
- ç§»é™¤é‡å¤æ•°æ®
- ç§»é™¤æ ¼å¼é”™è¯¯çš„æ•°æ®
- ç§»é™¤ä¸ç›¸å…³çš„æ•°æ®
- éªŒè¯ç­”æ¡ˆçš„æ­£ç¡®æ€§
```

### 5. SFT åéªŒè¯

```bash
# SFT è®­ç»ƒå®Œæˆåï¼ŒåŠ¡å¿…éªŒè¯æ•ˆæœ

# æ–¹æ³• 1: åœ¨éªŒè¯é›†ä¸Šè®¡ç®— loss
python3 -m verl.trainer.fsdp_sft_trainer \
    --eval_only \
    --checkpoint ./checkpoints/qwen7b_sft

# æ–¹æ³• 2: ç”Ÿæˆæ ·ä¾‹å¹¶äººå·¥æ£€æŸ¥
python generate_samples.py \
    --model ./checkpoints/qwen7b_sft \
    --num_samples 100

# æ–¹æ³• 3: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡
python evaluate.py \
    --model ./checkpoints/qwen7b_sft \
    --test_file ~/data/gsm8k/test.parquet
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: SFT loss ä¸ä¸‹é™æ€ä¹ˆåŠï¼Ÿ

**å¯èƒ½åŸå› ï¼š**

```bash
# 1. å­¦ä¹ ç‡å¤ªå°
optim.lr=1e-5  # å°è¯•å¢å¤§åˆ° 5e-5

# 2. å­¦ä¹ ç‡å¤ªå¤§ï¼ˆloss éœ‡è¡ï¼‰
optim.lr=5e-7  # å°è¯•å‡å°åˆ° 1e-6

# 3. Batch size å¤ªå°
data.train_batch_size=128  # å¢å¤§ batch size
gradient_accumulation_steps=4  # æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

# 4. æ•°æ®è´¨é‡é—®é¢˜
# æ£€æŸ¥æ•°æ®ï¼š
python -c "
import pandas as pd
df = pd.read_parquet('~/data/gsm8k_sft/train.parquet')
print(df.head())
print(df['response'].apply(len).describe())  # æ£€æŸ¥é•¿åº¦åˆ†å¸ƒ
"

# 5. æ¨¡å‹æƒé‡åŠ è½½é—®é¢˜
# æ£€æŸ¥æ˜¯å¦æ­£ç¡®åŠ è½½äº†é¢„è®­ç»ƒæƒé‡
model.path=Qwen/Qwen2.5-7B-Instruct  # ç¡®è®¤è·¯å¾„æ­£ç¡®
```

### Q2: SFT è¿‡æ‹Ÿåˆæ€ä¹ˆåŠï¼Ÿ

**ç—‡çŠ¶ï¼š**
```
è®­ç»ƒ loss æŒç»­ä¸‹é™ï¼Œä½†éªŒè¯ loss ä¸Šå‡
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# 1. å‡å°‘è®­ç»ƒè½®æ•°
trainer.total_epochs=5  # ä» 10 å‡å°åˆ° 5

# 2. å¢åŠ æ­£åˆ™åŒ–
optim.weight_decay=0.1  # ä» 0.01 å¢å¤§åˆ° 0.1

# 3. ä½¿ç”¨ Dropout
model.dropout=0.1

# 4. ä½¿ç”¨ LoRAï¼ˆå¤©ç„¶æ­£åˆ™åŒ–ï¼‰
model.peft_config.enable=True
model.peft_config.r=8  # å‡å° rank

# 5. å¢åŠ æ•°æ®é‡
# ä½¿ç”¨æ•°æ®å¢å¼ºæˆ–è·å–æ›´å¤šæ•°æ®

# 6. Early stopping
# ç›‘æ§éªŒè¯ lossï¼Œä¸å†ä¸‹é™æ—¶åœæ­¢
```

### Q3: OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# 1. å‡å° batch size
data.train_batch_size=64  # ä» 128 å‡å°

# 2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.fsdp_config.gradient_checkpointing=True

# 3. ä½¿ç”¨ LoRA
model.peft_config.enable=True

# 4. å¯ç”¨å‚æ•°å¸è½½ï¼ˆä¼šå˜æ…¢ï¼‰
model.fsdp_config.param_offload=True
model.fsdp_config.optimizer_offload=True

# 5. ä½¿ç”¨æ··åˆç²¾åº¦
trainer.mixed_precision=True

# 6. å‡å°åºåˆ—é•¿åº¦
data.max_prompt_length=512  # ä» 1024 å‡å°
data.max_response_length=256  # ä» 512 å‡å°

# 7. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
gradient_accumulation_steps=4
# è¿™æ ·å¯ä»¥å‡å°æ¯æ­¥çš„ batch sizeï¼Œä½†ä¿æŒæœ‰æ•ˆ batch size
```

### Q4: SFT å RL æ•ˆæœåè€Œå˜å·®ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**

```bash
# 1. SFT è¿‡æ‹Ÿåˆå¯¼è‡´æ¨¡å‹å¤±å»å¤šæ ·æ€§
# è§£å†³ï¼šå‡å°‘ SFT è®­ç»ƒè½®æ•°

# 2. SFT æ•°æ®åˆ†å¸ƒä¸ RL ä»»åŠ¡ä¸åŒ¹é…
# è§£å†³ï¼šæ£€æŸ¥æ•°æ®ä¸€è‡´æ€§

# 3. SFT å­¦ä¹ ç‡å¤ªå¤§ï¼Œç ´åäº†é¢„è®­ç»ƒçŸ¥è¯†
# è§£å†³ï¼šå‡å°å­¦ä¹ ç‡ï¼ˆå¦‚ 1e-6ï¼‰

# 4. RL å­¦ä¹ ç‡è®¾ç½®ä¸å½“
# è§£å†³ï¼šRL å­¦ä¹ ç‡åº”è¯¥æ¯” SFT æ›´å°
actor_rollout_ref.actor.optim.lr=5e-7  # SFT ç”¨çš„æ˜¯ 5e-6

# 5. æ²¡æœ‰æ­£ç¡®åŠ è½½ SFT checkpoint
# è§£å†³ï¼šç¡®è®¤è·¯å¾„å’ŒåŠ è½½æ–¹å¼
actor_rollout_ref.model.path=./checkpoints/qwen7b_sft/checkpoint-final
```

### Q5: å¤šè½®å¯¹è¯ SFT å¦‚ä½•é…ç½®ï¼Ÿ

**æ•°æ®æ ¼å¼ï¼š**

```python
# å¤šè½®å¯¹è¯ SFT æ•°æ®
{
    "prompt": [
        {"role": "user", "content": "ç¬¬ä¸€ä¸ªé—®é¢˜"},
        {"role": "assistant", "content": "ç¬¬ä¸€ä¸ªå›ç­”"},
        {"role": "user", "content": "ç¬¬äºŒä¸ªé—®é¢˜"}
    ],
    "response": "ç¬¬äºŒä¸ªå›ç­”",  # åªéœ€è¦æ ‡æ³¨æœ€åä¸€è½®
    "data_source": "multiturn_sft"
}
```

**è®­ç»ƒé…ç½®ï¼š**

```bash
python3 -m verl.trainer.fsdp_sft_trainer \
    data.train_files=$HOME/data/multiturn_sft/train.parquet \
    data.max_prompt_length=2048 \  # å¤šè½®å¯¹è¯éœ€è¦æ›´é•¿
    # å…¶ä»–å‚æ•°åŒå•è½®
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### Qwen2.5-0.5B GSM8K SFT

```
è®­ç»ƒå‰å‡†ç¡®ç‡: 36.4%
SFT åå‡†ç¡®ç‡: 52.8%
SFT + RL å‡†ç¡®ç‡: 56.7%

SFT é…ç½®:
- lr: 1e-5
- epochs: 10
- batch_size: 128
- è®­ç»ƒæ—¶é—´: ~20 åˆ†é’Ÿï¼ˆ2x A100ï¼‰
```

### Qwen2-7B GSM8K SFT

```
è®­ç»ƒå‰å‡†ç¡®ç‡: 65.2%
SFT åå‡†ç¡®ç‡: 72.1%
SFT + RL å‡†ç¡®ç‡: 78.5%

SFT é…ç½®:
- lr: 5e-6
- epochs: 8
- batch_size: 64
- è®­ç»ƒæ—¶é—´: ~1 å°æ—¶ï¼ˆ4x A100ï¼‰
```

---

## ğŸ”— å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [FSDP æ–‡æ¡£](https://pytorch.org/docs/stable/fsdp.html)
- [LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)

### å­¦ä¹ ç¬”è®°

- [01_å¿«é€Ÿä¸Šæ‰‹](../../learning_notes/01_å¿«é€Ÿä¸Šæ‰‹/) - ç¯å¢ƒå®‰è£…
- [02_æ•°æ®å‡†å¤‡](../../learning_notes/02_æ•°æ®å‡†å¤‡/) - SFT æ•°æ®æ ¼å¼

### ç›¸å…³ç¤ºä¾‹

- `examples/ppo_trainer/` - PPO RL è®­ç»ƒï¼ˆSFT åçš„ä¸‹ä¸€æ­¥ï¼‰
- `examples/grpo_trainer/` - GRPO RL è®­ç»ƒ
- `examples/data_preprocess/` - æ•°æ®é¢„å¤„ç†

---

**åˆ›å»ºæ—¶é—´**: 2026-01-28
**é€‚ç”¨ç‰ˆæœ¬**: verl v0.2+
**ç»´æŠ¤è€…**: verl team
