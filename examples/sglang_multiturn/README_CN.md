# SGLang å¤šè½®å¯¹è¯è®­ç»ƒ (Multi-Turn with SGLang)

> ä½¿ç”¨ SGLang è¿›è¡Œå¤šè½®å¯¹è¯å’Œå·¥å…·è°ƒç”¨çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒ

---

## ğŸ“‹ æ¦‚è¿°

æœ¬ç›®å½•åŒ…å«ä½¿ç”¨ **SGLang** ä½œä¸ºæ¨ç†å¼•æ“è¿›è¡Œå¤šè½®å¯¹è¯å’Œå·¥å…·è°ƒç”¨è®­ç»ƒçš„ç¤ºä¾‹ã€‚SGLang é’ˆå¯¹å¤šè½®å¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ï¼Œç‰¹åˆ«é€‚åˆ Agent RL è®­ç»ƒã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… **å¤šè½®å¯¹è¯æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒå¤šè½®äº¤äº’ï¼Œæ— éœ€å¤æ‚é…ç½®
- âœ… **å·¥å…·è°ƒç”¨**ï¼šæ”¯æŒ function calling å’Œ tool use
- âœ… **é«˜æ•ˆçš„ KV ç¼“å­˜**ï¼šRadixAttention ç®—æ³•ï¼Œé‡ç”¨å†å²è®¡ç®—
- âœ… **å¼‚æ­¥æ‰§è¡Œ**ï¼šAgent Loop å¼‚æ­¥ä¼˜åŒ–ï¼Œæé«˜ GPU åˆ©ç”¨ç‡
- âœ… **çµæ´»çš„é‡‡æ ·**ï¼šæ”¯æŒå„ç§é‡‡æ ·ç­–ç•¥å’Œçº¦æŸ

### é€‚ç”¨åœºæ™¯

| åœºæ™¯ | è¯´æ˜ | æ¨èåº¦ |
|------|------|--------|
| **Agent RL è®­ç»ƒ** | å·¥å…·è°ƒç”¨ + å¤šè½®å¯¹è¯ | â­â­â­â­â­ |
| **å¤šè½®å¯¹è¯ä¼˜åŒ–** | è¶…è¿‡ 2 è½®çš„å¯¹è¯ | â­â­â­â­â­ |
| **GSM8K Tool Agent** | å¸¦è®¡ç®—å™¨å·¥å…·çš„æ•°å­¦é—®é¢˜ | â­â­â­â­â­ |
| **æœç´¢å¢å¼ºç”Ÿæˆ** | éœ€è¦è°ƒç”¨æœç´¢ API | â­â­â­â­â­ |
| **ä»£ç æ‰§è¡Œ Agent** | éœ€è¦è¿è¡Œä»£ç å¹¶è§‚å¯Ÿç»“æœ | â­â­â­â­ |
| **å•è½®å¯¹è¯** | ç®€å•ä»»åŠ¡ï¼ŒvLLM ä¹Ÿå¯ä»¥ | â­â­ |

### SGLang vs vLLM

| ç‰¹æ€§ | SGLang | vLLM |
|------|--------|------|
| **å¤šè½®å¯¹è¯** | â­â­â­â­â­ åŸç”Ÿä¼˜åŒ– | â­â­â­ æ”¯æŒä½†æ•ˆç‡ä¸€èˆ¬ |
| **å·¥å…·è°ƒç”¨** | â­â­â­â­â­ å®Œæ•´æ”¯æŒ | â­â­â­ éœ€è¦é¢å¤–å¤„ç† |
| **KV ç¼“å­˜** | RadixAttention | PagedAttention |
| **å•è½®æ€§èƒ½** | â­â­â­â­ | â­â­â­â­â­ |
| **ç”Ÿæ€æˆç†Ÿåº¦** | â­â­â­ è¾ƒæ–° | â­â­â­â­â­ æˆç†Ÿ |
| **æ¨èåœºæ™¯** | å¤šè½® + Agent | å•è½® + æ‰¹é‡æ¨ç† |

---

## ğŸ”§ å‰ç½®æ¡ä»¶

### ç¡¬ä»¶è¦æ±‚

```
æœ€ä½é…ç½®ï¼š
- GPU: 4 å¼  24GB GPUï¼ˆå¦‚ RTX 3090ï¼‰
- å†…å­˜: 64GB
- å­˜å‚¨: 100GB

æ¨èé…ç½®ï¼š
- GPU: 8 å¼  40GB GPUï¼ˆå¦‚ A100ï¼‰
- å†…å­˜: 128GB+
- å­˜å‚¨: 200GB+
```

### è½¯ä»¶ä¾èµ–

```bash
# å®‰è£… verl å¸¦ SGLang
pip install -e .[test,sglang]

# éªŒè¯ SGLang å®‰è£…
python -c "import sglang; print(sglang.__version__)"

# å¯é€‰ï¼šå®‰è£…é¢å¤–çš„å·¥å…·ä¾èµ–
pip install sympy  # ç”¨äºæ•°å­¦è®¡ç®—å·¥å…·
```

### æ•°æ®å‡†å¤‡

ä¸åŒä»»åŠ¡éœ€è¦ä¸åŒçš„æ•°æ®æ ¼å¼ï¼š

#### 1. GSM8K å·¥å…·è°ƒç”¨æ•°æ®

```bash
# å¤„ç†å¸¦å·¥å…·è°ƒç”¨çš„ GSM8K æ•°æ®
python examples/data_preprocess/gsm8k_multiturn_w_tool.py \
    --local_save_dir ~/data/gsm8k_tool

# éªŒè¯æ•°æ®
python -c "
import pandas as pd
df = pd.read_parquet('~/data/gsm8k_tool/train.parquet')
print('æ ·ä¾‹æ•°æ®:')
print(df.iloc[0]['prompt'])
"

# è¾“å‡ºç¤ºä¾‹ï¼ˆå¤šè½®æ ¼å¼ï¼‰ï¼š
# [
#   {'role': 'user', 'content': 'Natalia sold clips to...'},
#   {'role': 'assistant', 'content': 'Let me calculate...'},
#   {'role': 'tool', 'content': '48', 'name': 'calculator'}
# ]
```

#### 2. å¤šè½®äº¤äº’æ•°æ®

```bash
# å¤„ç†å¤šè½®äº¤äº’æ•°æ®ï¼ˆæ— å·¥å…·ï¼‰
python examples/data_preprocess/gsm8k_multiturn_w_interaction.py \
    --local_save_dir ~/data/gsm8k_multiturn

# è¾“å‡ºæ ¼å¼ï¼ˆå¤šè½®å¯¹è¯ï¼‰ï¼š
# [
#   {'role': 'user', 'content': 'Question...'},
#   {'role': 'assistant', 'content': 'Let me think...'},
#   {'role': 'user', 'content': 'Continue...'},
# ]
```

#### 3. Agent Loop æ•°æ®

```bash
# å¤„ç† Agent Loop æ•°æ®ï¼ˆæ¨èï¼‰
python examples/data_preprocess/gsm8k_tool_agent_loop.py \
    --local_save_dir ~/data/gsm8k_agent_loop
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¤ºä¾‹ 1ï¼šGSM8K å¤šè½®å·¥å…·è°ƒç”¨ï¼ˆæ¨èï¼‰

```bash
# 8 GPU æ ‡å‡†é…ç½®
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_multiturn.sh

# 4 GPU é…ç½®ï¼ˆå¦‚æœåªæœ‰ 4 å¼  GPUï¼‰
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_multiturn_4xgpu.sh
```

**é¢„æœŸè¾“å‡ºï¼š**
```
[2026-01-28 10:00:00] Initializing SGLang server...
[2026-01-28 10:00:10] SGLang server started on port 30000
[2026-01-28 10:00:15] Starting Agent Loop training...

Epoch 0:
  agent_loop_rollout: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [01:30<00:00]
  train_actor: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00]
  metrics: reward_mean=0.32, tool_call_success=0.95

âœ… è®­ç»ƒå®Œæˆï¼
```

### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ Server æ¨¡å¼ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

```bash
# å…ˆå¯åŠ¨ SGLang server
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_multiturn_server.sh

# Server ä¼šæŒç»­è¿è¡Œï¼Œæ—¥å¿—ï¼š
# SGLang Server listening on 0.0.0.0:30000
# Ready to accept requests
```

### ç¤ºä¾‹ 3ï¼šä½¿ç”¨ vLLM + FSDP æ··åˆæ¨¡å¼

```bash
# Rollout ç”¨ vLLMï¼Œè®­ç»ƒç”¨ FSDP
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_multiturn_vllm_fsdp.sh

# é€‚åˆï¼šå¤šè½®å¯¹è¯ä¸å¤šï¼Œä½†éœ€è¦ FSDP è®­ç»ƒ
```

### ç¤ºä¾‹ 4ï¼šCurriculum Learningï¼ˆè¯¾ç¨‹å­¦ä¹ ï¼‰

```bash
# ä»ç®€å•åˆ°å›°éš¾é€æ­¥è®­ç»ƒ
bash examples/sglang_multiturn/run_qwen0.5b_gsm8k_multiturn_curriculum.sh

# è®­ç»ƒæµç¨‹ï¼š
# 1. å…ˆè®­ç»ƒç®€å•çš„å•æ­¥é—®é¢˜
# 2. é€æ­¥å¢åŠ éš¾åº¦
# 3. æœ€åè®­ç»ƒå¤æ‚çš„å¤šæ­¥é—®é¢˜
```

---

## ğŸ“– è¯¦ç»†é…ç½®

### æ ¸å¿ƒé…ç½®å‚æ•°

#### 1. SGLang Rollout é…ç½®

```yaml
actor_rollout_ref:
  rollout:
    name: sglang                    # ä½¿ç”¨ SGLang å¼•æ“

    # Server é…ç½®
    mode: standalone                # standalone æˆ– server
    port_start: 30000               # Server èµ·å§‹ç«¯å£

    # å¹¶è¡Œé…ç½®
    tensor_model_parallel_size: 2   # å¼ é‡å¹¶è¡Œ
    data_parallel_size: 1           # æ•°æ®å¹¶è¡Œ

    # æ˜¾å­˜é…ç½®
    gpu_memory_utilization: 0.6     # GPU æ˜¾å­˜åˆ©ç”¨ç‡

    # Agent Loop é…ç½®ï¼ˆå¤šè½®ï¼‰
    use_agent_loop: True            # å¯ç”¨ Agent Loop
    max_turns: 10                   # æœ€å¤§è½®æ¬¡
    stop_on_tool_success: True      # å·¥å…·è°ƒç”¨æˆåŠŸååœæ­¢
```

#### 2. Agent Loop é…ç½®

```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šè‡ªå®šä¹‰ Agent Loop
actor_rollout_ref:
  rollout:
    agent_loop_class: "examples.sglang_multiturn.gsm8k_toolcall_shaping.agent_loop.GSM8KToolAgentLoop"

    # Agent Loop å‚æ•°
    agent_loop_config:
      max_turns: 10                 # æœ€å¤§å¯¹è¯è½®æ¬¡
      tools: ["calculator"]         # å¯ç”¨å·¥å…·åˆ—è¡¨
      stop_on_correct: True         # ç­”æ¡ˆæ­£ç¡®ååœæ­¢
```

#### 3. å·¥å…·é…ç½®

```yaml
# åœ¨ Agent Loop ä¸­é…ç½®å·¥å…·
tools:
  - name: calculator
    description: "A calculator that can evaluate mathematical expressions"
    parameters:
      type: object
      properties:
        expression:
          type: string
          description: "The mathematical expression to evaluate"
```

#### 4. Reward Shaping é…ç½®

```yaml
reward_shaping:
  enable: True

  # è¿‡ç¨‹å¥–åŠ±
  intermediate_rewards:
    tool_call_success: 0.1      # æˆåŠŸè°ƒç”¨å·¥å…·
    valid_reasoning: 0.05       # æœ‰æ•ˆæ¨ç†æ­¥éª¤

  # æƒ©ç½š
  penalties:
    invalid_tool_call: -0.1     # æ— æ•ˆå·¥å…·è°ƒç”¨
    max_turns_exceeded: -0.5    # è¶…è¿‡æœ€å¤§è½®æ¬¡
    redundant_tool_call: -0.05  # é‡å¤è°ƒç”¨å·¥å…·
```

---

## ğŸ’¡ è¿è¡Œç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šQwen2.5-3B GSM8K å·¥å…·è°ƒç”¨ï¼ˆ8 GPUï¼‰

```bash
# å®Œæ•´é…ç½®
python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=grpo \
    data.train_files=$HOME/data/gsm8k_tool/train.parquet \
    data.val_files=$HOME/data/gsm8k_tool/test.parquet \
    data.train_batch_size=256 \
    \
    actor_rollout_ref.model.path=Qwen/Qwen2.5-3B-Instruct \
    \
    actor_rollout_ref.rollout.name=sglang \
    actor_rollout_ref.rollout.use_agent_loop=True \
    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
    actor_rollout_ref.rollout.n=4 \
    \
    actor_rollout_ref.actor.ppo_mini_batch_size=256 \
    actor_rollout_ref.actor.use_kl_loss=True \
    actor_rollout_ref.actor.kl_loss_coef=0.001 \
    \
    trainer.n_gpus_per_node=8 \
    trainer.total_epochs=20

# é¢„æœŸç»“æœï¼š
# - è®­ç»ƒæ—¶é—´: ~2 å°æ—¶
# - GSM8K å‡†ç¡®ç‡: 75-80%
# - å·¥å…·è°ƒç”¨æˆåŠŸç‡: 95%+
```

### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ MLflow è·Ÿè¸ªå®éªŒ

```bash
# å¯ç”¨ MLflow
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_tool_agent_mlflow.sh

# MLflow UIï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰
mlflow ui --port 5000

# è®¿é—® http://localhost:5000 æŸ¥çœ‹å®éªŒ
```

### ç¤ºä¾‹ 3ï¼šDAPO å¤šè½®è®­ç»ƒ

```bash
# DAPOï¼ˆDeliberative Alignment with Partial Observationsï¼‰
bash examples/sglang_multiturn/run_qwen3_4b_dapo_multiturn.sh

# DAPO ç‰¹ç‚¹ï¼š
# - éƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒ
# - å»¶è¿Ÿå¥–åŠ±
# - éœ€è¦è§„åˆ’å’Œæ¨ç†
```

### ç¤ºä¾‹ 4ï¼šGeo3K å‡ ä½•é—®é¢˜ï¼ˆå›¾åƒ + å·¥å…·ï¼‰

```bash
# å¤šæ¨¡æ€ï¼šå›¾åƒ + æ–‡æœ¬ + å·¥å…·è°ƒç”¨
cd examples/sglang_multiturn/geo3k
python run_geo3k_agent.py

# æ•°æ®æ ¼å¼ï¼š
# {
#   "prompt": [
#     {"type": "image", "image": "/path/to/geometry.png"},
#     {"type": "text", "text": "Find the angle..."}
#   ],
#   "tools": ["geometry_calculator", "angle_solver"]
# }
```

### ç¤ºä¾‹ 5ï¼šSearch R1-like è®­ç»ƒ

```bash
# ç±»ä¼¼ R1 æ¨¡å‹çš„æœç´¢å¢å¼ºè®­ç»ƒ
cd examples/sglang_multiturn/search_r1_like
bash run_search_r1.sh

# å·¥å…·ï¼šæœç´¢å¼•æ“ API
# æ•°æ®ï¼šéœ€è¦å¤–éƒ¨çŸ¥è¯†çš„é—®é¢˜
# æµç¨‹ï¼šæ€è€ƒ â†’ æœç´¢ â†’ æ•´åˆ â†’ å›ç­”
```

---

## ğŸ¯ Agent Loop å¼€å‘æŒ‡å—

### è‡ªå®šä¹‰ Agent Loop

#### 1. åˆ›å»º Agent Loop ç±»

```python
# my_agent_loop.py
from verl.workers.rollout.sglang_rollout.agent_loop.base import AgentLoopBase
from verl.protocol import DataProto

class MyAgentLoop(AgentLoopBase):
    """è‡ªå®šä¹‰ Agent Loop"""

    def __init__(self, max_turns=10):
        self.max_turns = max_turns

    async def generate(
        self,
        llm_server,
        data: DataProto,
        **kwargs
    ) -> DataProto:
        """
        æ ¸å¿ƒç”Ÿæˆé€»è¾‘

        Args:
            llm_server: LLM æ¨ç†æœåŠ¡
            data: è¾“å…¥æ•°æ®ï¼ˆåŒ…å« promptï¼‰

        Returns:
            DataProto: è¾“å‡ºæ•°æ®ï¼ˆåŒ…å«å®Œæ•´å¯¹è¯å†å²ï¼‰
        """
        # 1. åˆå§‹åŒ–
        prompts = data.batch['prompt']
        trajectories = []

        # 2. å¤šè½®å¯¹è¯å¾ªç¯
        for prompt_idx, prompt in enumerate(prompts):
            history = prompt.copy()  # ä¿ç•™åˆå§‹ prompt

            for turn in range(self.max_turns):
                # 2.1 LLM ç”Ÿæˆ
                response = await llm_server.generate(
                    prompts=[history],
                    **kwargs
                )

                # 2.2 æ·»åŠ  assistant å“åº”
                history.append({
                    'role': 'assistant',
                    'content': response['text'][0]
                })

                # 2.3 æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
                tool_call = self._parse_tool_call(response['text'][0])

                if tool_call is None:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
                    break

                # 2.4 æ‰§è¡Œå·¥å…·
                tool_result = self._execute_tool(tool_call)

                # 2.5 æ·»åŠ å·¥å…·å“åº”
                history.append({
                    'role': 'tool',
                    'content': tool_result,
                    'name': tool_call['name']
                })

                # 2.6 æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if self._is_complete(history):
                    break

            trajectories.append(history)

        # 3. æ„é€ è¿”å›æ•°æ®
        output_data = data.clone()
        output_data.batch['response'] = trajectories

        return output_data

    def _parse_tool_call(self, text):
        """è§£æå·¥å…·è°ƒç”¨"""
        # ç¤ºä¾‹ï¼šæ£€æµ‹ "calculator(123+456)" æ ¼å¼
        import re
        match = re.search(r'calculator\((.*?)\)', text)
        if match:
            return {
                'name': 'calculator',
                'arguments': {'expression': match.group(1)}
            }
        return None

    def _execute_tool(self, tool_call):
        """æ‰§è¡Œå·¥å…·"""
        if tool_call['name'] == 'calculator':
            expr = tool_call['arguments']['expression']
            try:
                result = eval(expr)  # æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å®‰å…¨çš„æ±‚å€¼
                return str(result)
            except Exception as e:
                return f"Error: {str(e)}"
        return "Unknown tool"

    def _is_complete(self, history):
        """æ£€æŸ¥æ˜¯å¦å®Œæˆ"""
        # ç¤ºä¾‹ï¼šæ£€æŸ¥æœ€åä¸€ä¸ªå“åº”æ˜¯å¦åŒ…å« "Final Answer"
        if history and history[-1]['role'] == 'assistant':
            return 'Final Answer' in history[-1]['content']
        return False
```

#### 2. æ³¨å†Œ Agent Loop

```python
# åœ¨é…ç½®ä¸­æŒ‡å®š
actor_rollout_ref.rollout.agent_loop_class = "path.to.MyAgentLoop"
```

#### 3. å®ç° Reward Shaping

```python
# my_reward_shaper.py
from verl.trainer.ppo.reward_score.base import RewardManager

@RewardManager.register('my_task')
def compute_reward(data):
    """è®¡ç®—å¥–åŠ±ï¼ˆåŒ…å« shapingï¼‰"""
    rewards = []

    for trajectory in data['trajectories']:
        total_reward = 0

        # ç»“æœå¥–åŠ±
        if is_correct(trajectory):
            total_reward += 1.0

        # è¿‡ç¨‹å¥–åŠ±
        for turn in trajectory:
            if turn['role'] == 'tool' and is_valid_tool_call(turn):
                total_reward += 0.1  # æˆåŠŸè°ƒç”¨å·¥å…·

            if turn['role'] == 'assistant' and has_good_reasoning(turn):
                total_reward += 0.05  # å¥½çš„æ¨ç†æ­¥éª¤

        # æƒ©ç½š
        if len(trajectory) > max_turns:
            total_reward -= 0.5  # è¶…è¿‡æœ€å¤§è½®æ¬¡

        rewards.append(total_reward)

    return rewards
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: SGLang server å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶ï¼š**
```
Error: Failed to start SGLang server
æˆ–
ConnectionError: Cannot connect to port 30000
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# 1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
lsof -i:30000
# å¦‚æœè¢«å ç”¨ï¼Œæ›´æ¢ç«¯å£
actor_rollout_ref.rollout.port_start=30100

# 2. æ£€æŸ¥ SGLang å®‰è£…
python -c "import sglang; print(sglang.__version__)"

# 3. æ‰‹åŠ¨å¯åŠ¨ server æµ‹è¯•
python -m sglang.launch_server \
    --model-path Qwen/Qwen2.5-3B-Instruct \
    --port 30000 \
    --tp 2

# 4. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
actor_rollout_ref.rollout.log_level=DEBUG
```

### Q2: Agent Loop æ— é™å¾ªç¯

**ç—‡çŠ¶ï¼š**
```
Warning: Agent Loop exceeded max_turns (10)
æˆ–
è®­ç»ƒå¡ä½ä¸åŠ¨
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ–¹æ³• 1: è®¾ç½®æ›´ä¸¥æ ¼çš„åœæ­¢æ¡ä»¶
actor_rollout_ref.rollout.max_turns=5  # å‡å°æœ€å¤§è½®æ¬¡

# æ–¹æ³• 2: æ·»åŠ è¶…æ—¶
actor_rollout_ref.rollout.timeout_per_turn=30  # æ¯è½®æœ€å¤š 30 ç§’

# æ–¹æ³• 3: æ”¹è¿›åœæ­¢é€»è¾‘
# åœ¨ Agent Loop ä¸­æ·»åŠ ï¼š
def _is_complete(self, history):
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ€ç»ˆç­”æ¡ˆ
    if 'Final Answer' in history[-1]['content']:
        return True

    # æ£€æŸ¥æ˜¯å¦é‡å¤
    if self._has_repetition(history):
        return True

    # æ£€æŸ¥å·¥å…·è°ƒç”¨å¤±è´¥æ¬¡æ•°
    if self._tool_failure_count(history) >= 3:
        return True

    return False

# æ–¹æ³• 4: ä½¿ç”¨ EOS token
actor_rollout_ref.rollout.stop_strings=['<|im_end|>', '##DONE##']
```

### Q3: å·¥å…·è°ƒç”¨å¤±è´¥ç‡é«˜

**ç—‡çŠ¶ï¼š**
```
tool_call_success_rate: 0.3
æˆ–
å¤§é‡ "Invalid tool call" é”™è¯¯
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# 1. æ”¹è¿› promptï¼ˆåœ¨æ•°æ®ä¸­æ·»åŠ å·¥å…·ä½¿ç”¨ç¤ºä¾‹ï¼‰
# ç¤ºä¾‹ï¼š
"You can use tools in the following format:
calculator(expression)

Example:
User: What is 123 + 456?
Assistant: Let me calculate: calculator(123 + 456)
Tool: 579
Assistant: The answer is 579."

# 2. ä½¿ç”¨ Few-shot examples
# åœ¨ system prompt ä¸­æ·»åŠ å·¥å…·è°ƒç”¨ç¤ºä¾‹

# 3. Reward shapingï¼ˆå¥–åŠ±æ­£ç¡®çš„å·¥å…·è°ƒç”¨æ ¼å¼ï¼‰
reward_shaping.tool_format_reward=0.05

# 4. ä½¿ç”¨æ”¯æŒ function calling çš„æ¨¡å‹
actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct  # æ›´å¥½çš„å·¥å…·è°ƒç”¨èƒ½åŠ›

# 5. Fine-tune å·¥å…·è°ƒç”¨æ ¼å¼ï¼ˆSFTï¼‰
# å…ˆç”¨ SFT è®­ç»ƒå·¥å…·è°ƒç”¨æ ¼å¼ï¼Œå†ç”¨ RL
```

### Q4: Trajectory é•¿åº¦ä¸ä¸€è‡´å¯¼è‡´è®­ç»ƒå¤±è´¥

**ç—‡çŠ¶ï¼š**
```
RuntimeError: expected all tensors to have the same size
æˆ–
shape mismatch in concat
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# åœ¨ Agent Loop ä¸­ç»Ÿä¸€é•¿åº¦ï¼š

def generate(self, llm_server, data, **kwargs):
    # ... ç”Ÿæˆ trajectories ...

    # Pad åˆ°ç»Ÿä¸€é•¿åº¦
    max_length = max(len(t) for t in trajectories)

    padded_trajectories = []
    for traj in trajectories:
        if len(traj) < max_length:
            # æ·»åŠ  padding
            padding = [{'role': 'padding', 'content': ''}] * (max_length - len(traj))
            traj = traj + padding
        padded_trajectories.append(traj)

    # æˆ–è€…ï¼šæˆªæ–­åˆ°å›ºå®šé•¿åº¦
    max_length = self.max_turns * 2  # user + assistant
    truncated_trajectories = [t[:max_length] for t in trajectories]
```

### Q5: SGLang vs vLLM æ€§èƒ½å¯¹æ¯”

**åŸºå‡†æµ‹è¯•ï¼ˆQwen2.5-3Bï¼ŒGSM8K å¤šè½®ï¼‰ï¼š**

```
å•è½®ä»»åŠ¡ï¼ˆn=1ï¼‰ï¼š
- vLLM:   100 samples/s
- SGLang:  95 samples/s
â†’ vLLM ç•¥å¿«

å¤šè½®ä»»åŠ¡ï¼ˆå¹³å‡ 3 è½®ï¼‰ï¼š
- vLLM:   30 samples/s
- SGLang: 65 samples/s
â†’ SGLang å¿« 2.2x

å·¥å…·è°ƒç”¨ä»»åŠ¡ï¼ˆå¹³å‡ 5 è½®ï¼‰ï¼š
- vLLM:   15 samples/s
- SGLang: 50 samples/s
â†’ SGLang å¿« 3.3x
```

**æ¨èï¼š**
- å•è½®ä»»åŠ¡ï¼švLLM
- å¤šè½®ä»»åŠ¡ï¼ˆ2+ è½®ï¼‰ï¼šSGLang
- å·¥å…·è°ƒç”¨ï¼šSGLang

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### Qwen2.5-3B GSM8K å·¥å…·è°ƒç”¨

```
é¢„è®­ç»ƒæ¨¡å‹å‡†ç¡®ç‡: ~52%
å¤šè½® RL è®­ç»ƒå: ~75%
å·¥å…·è°ƒç”¨æˆåŠŸç‡: 96%
è®­ç»ƒæ—¶é—´: ~2 å°æ—¶ï¼ˆ8x A100ï¼‰
é…ç½®: batch_size=256, n=4, epochs=20

å‘½ä»¤:
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_multiturn.sh
```

### Qwen3-4B GSM8K Agent Loop

```
é¢„è®­ç»ƒæ¨¡å‹å‡†ç¡®ç‡: ~65%
Agent Loop è®­ç»ƒå: ~82%
å¹³å‡è½®æ¬¡: 2.8 è½®
è®­ç»ƒæ—¶é—´: ~3 å°æ—¶ï¼ˆ8x A100ï¼‰

å‘½ä»¤:
bash examples/sglang_multiturn/run_qwen3-4b_gsm8k_multiturn.sh
```

---

## ğŸ”— å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [SGLang GitHub](https://github.com/sgl-project/sglang)
- [SGLang æ–‡æ¡£](https://sgl-project.github.io/)
- [verl Agent Loop æ–‡æ¡£](../../docs/sglang_multiturn/)

### å­¦ä¹ ç¬”è®°

- [05_Agent_RL/Agent_Loopè¯¦è§£.md](../../learning_notes/05_Agent_RL/Agent_Loopè¯¦è§£.md) - Agent Loop ç³»ç»Ÿæ·±åº¦è§£æ
- [05_Agent_RL/README.md](../../learning_notes/05_Agent_RL/README.md) - Agent RL æ¦‚è§ˆ

### ç›¸å…³ç¤ºä¾‹

- `examples/tutorial/agent_loop_get_started/` - Agent Loop å…¥é—¨æ•™ç¨‹
- `examples/data_preprocess/gsm8k_tool_agent_loop.py` - Agent Loop æ•°æ®å¤„ç†
- `examples/ppo_trainer/` - PPO è®­ç»ƒï¼ˆå•è½®ï¼‰
- `examples/grpo_trainer/` - GRPO è®­ç»ƒï¼ˆå•è½®ï¼‰

---

**åˆ›å»ºæ—¶é—´**: 2026-01-28
**é€‚ç”¨ç‰ˆæœ¬**: verl v0.2+
**ç»´æŠ¤è€…**: verl team
