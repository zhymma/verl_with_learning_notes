# 01 - å¿«é€Ÿä¸Šæ‰‹

> ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå®‰è£…ï¼Œç†è§£è®­ç»ƒæµç¨‹å’Œé…ç½®ç³»ç»Ÿ

---

## ğŸ“š æœ¬ç« å†…å®¹

### ğŸ“– å­¦ä¹ ç¬”è®°

#### **01_å¿«é€Ÿä¸Šæ‰‹.md** - åŸºç¡€å…¥é—¨ï¼ˆ8000+ å­—ï¼‰
- ç¯å¢ƒå®‰è£…ä¸éªŒè¯
- æ¨¡å‹å’Œæ•°æ®å‡†å¤‡
- ç¬¬ä¸€æ¬¡ GRPO è®­ç»ƒ
- TensorBoard ç›‘æ§
- é—®é¢˜æ’æŸ¥

#### **ray_trainer_è¯¦è§£.md** - è®­ç»ƒä¸»å¾ªç¯æ·±åº¦è§£æï¼ˆæ–°ï¼ï¼‰
- RayPPOTrainer ç±»æ¶æ„
- åˆå§‹åŒ–æµç¨‹ï¼ˆResourcePool, WorkerGroupï¼‰
- è®­ç»ƒä¸»å¾ªç¯ï¼ˆfitï¼‰
- å•æ­¥è®­ç»ƒè¯¦è§£ï¼ˆ_train_step çš„ 7 ä¸ªé˜¶æ®µï¼‰
- æ•°æ®åœ¨å„é˜¶æ®µçš„å˜åŒ–
- å®Œæ•´çš„ GSM8K è®­ç»ƒä¾‹å­è¿½è¸ª
- è°ƒè¯•æŠ€å·§

#### **é…ç½®ç³»ç»Ÿè¯¦è§£.md** - Hydra é…ç½®æ·±åº¦è§£æï¼ˆæ–°ï¼ï¼‰
- Hydra é…ç½®ç³»ç»Ÿæ¦‚è§ˆ
- é…ç½®æ–‡ä»¶ç»“æ„å’ŒåŠ è½½é¡ºåº
- æ ¸å¿ƒé…ç½®é¡¹è¯¦è§£ï¼ˆData, Actor, Rollout, Algorithmï¼‰
- é…ç½®è¦†ç›–å’Œç»„åˆ
- å®é™…æ¡ˆä¾‹è§£æï¼ˆGRPO, PPO, å¤šæ•°æ®é›†ï¼‰
- é…ç½®è°ƒä¼˜æŠ€å·§
- å¸¸è§é…ç½®é”™è¯¯

### ğŸ› ï¸ æ ¸å¿ƒè„šæœ¬

- **check_env.sh** - ç¯å¢ƒä¾èµ–æ£€æŸ¥
- **check_data.py** - æ•°æ®æ ¼å¼éªŒè¯
- **run_first_training.sh** - ç¬¬ä¸€æ¬¡è®­ç»ƒï¼ˆæ¨¡æ¿ï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1ï¼šæ£€æŸ¥ç¯å¢ƒ

```bash
cd learning_notes/01_å¿«é€Ÿä¸Šæ‰‹
bash check_env.sh
```

### æ­¥éª¤ 2ï¼šå‡†å¤‡æ•°æ®

```bash
# ä¸‹è½½ GSM8K
python ../../examples/data_preprocess/gsm8k.py --local_dir ~/data/gsm8k

# éªŒè¯æ•°æ®
python check_data.py ~/data/gsm8k/train.parquet
```

### æ­¥éª¤ 3ï¼šå¼€å§‹è®­ç»ƒ

```bash
# ä¿®æ”¹ run_first_training.sh ä¸­çš„é…ç½®
# ç„¶åè¿è¡Œ
bash run_first_training.sh
```

---

## ğŸ“– æ¨èå­¦ä¹ è·¯å¾„

### ç¬¬ 1 å¤©ï¼šåŸºç¡€å…¥é—¨

1. **é˜…è¯»** `01_å¿«é€Ÿä¸Šæ‰‹.md`ï¼ˆ1 å°æ—¶ï¼‰
   - ç†è§£åŸºæœ¬æ¦‚å¿µ
   - äº†è§£è®­ç»ƒæµç¨‹

2. **å®è·µ** ç¯å¢ƒå®‰è£…å’Œæ•°æ®å‡†å¤‡ï¼ˆ2 å°æ—¶ï¼‰
   - è¿è¡Œ `check_env.sh`
   - ä¸‹è½½æ¨¡å‹å’Œæ•°æ®

3. **è¿è¡Œ** ç¬¬ä¸€æ¬¡è®­ç»ƒï¼ˆ2-4 å°æ—¶ï¼‰
   - ä½¿ç”¨ `run_first_training.sh`
   - è§‚å¯Ÿ TensorBoard

### ç¬¬ 2 å¤©ï¼šæ·±å…¥ç†è§£

1. **é˜…è¯»** `ray_trainer_è¯¦è§£.md`ï¼ˆ2 å°æ—¶ï¼‰
   - ç†è§£è®­ç»ƒä¸»å¾ªç¯
   - æŒæ¡ 7 ä¸ªè®­ç»ƒé˜¶æ®µ
   - è·Ÿè¸ªæ•°æ®æµè½¬

2. **å®è·µ** æ·»åŠ è°ƒè¯•è¾“å‡º
   ```python
   # åœ¨ verl/trainer/ppo/ray_trainer.py çš„ _train_step ä¸­æ·»åŠ 
   print(f"[Debug] Step {self.global_step}")
   print(f"  Batch size: {len(batch)}")
   print(f"  Reward mean: {rollout_output.batch['rewards'].mean()}")
   ```

### ç¬¬ 3 å¤©ï¼šé…ç½®è°ƒä¼˜

1. **é˜…è¯»** `é…ç½®ç³»ç»Ÿè¯¦è§£.md`ï¼ˆ2 å°æ—¶ï¼‰
   - ç†è§£ Hydra é…ç½®ç³»ç»Ÿ
   - æŒæ¡æ ¸å¿ƒé…ç½®é¡¹
   - å­¦ä¹ é…ç½®ç»„åˆ

2. **å®è·µ** å‚æ•°è°ƒä¼˜
   ```bash
   # å°è¯•ä¸åŒå­¦ä¹ ç‡
   python3 -m verl.trainer.main_ppo \
       actor_rollout_ref.actor.optim.lr=5e-7  # ä» 1e-6 æ”¹ä¸º 5e-7

   # å°è¯•ä¸åŒ batch size
   python3 -m verl.trainer.main_ppo \
       data.train_batch_size=128  # ä» 256 æ”¹ä¸º 128
   ```

---

## ğŸ“‹ å­¦ä¹ æ£€æŸ¥æ¸…å•

### åŸºç¡€å…¥é—¨ âœ“
- [ ] æˆåŠŸå®‰è£… verl å’Œä¾èµ–
- [ ] ä¸‹è½½ Qwen2.5-7B æ¨¡å‹
- [ ] å‡†å¤‡ GSM8K æ•°æ®
- [ ] è¿è¡Œç¬¬ä¸€æ¬¡è®­ç»ƒï¼ˆè‡³å°‘ 1 ä¸ª epochï¼‰
- [ ] ä½¿ç”¨ TensorBoard æŸ¥çœ‹è®­ç»ƒæ›²çº¿

### è®­ç»ƒæµç¨‹ç†è§£ âœ“
- [ ] ç†è§£ RayPPOTrainer çš„æ¶æ„
- [ ] æŒæ¡åˆå§‹åŒ–æµç¨‹ï¼ˆResourcePool, WorkerGroupï¼‰
- [ ] ç†è§£ _train_step çš„ 7 ä¸ªé˜¶æ®µ
- [ ] èƒ½å¤Ÿè¿½è¸ªæ•°æ®åœ¨å„é˜¶æ®µçš„å˜åŒ–
- [ ] çŸ¥é“å¦‚ä½•è°ƒè¯•è®­ç»ƒæµç¨‹

### é…ç½®ç³»ç»ŸæŒæ¡ âœ“
- [ ] ç†è§£ Hydra defaults æœºåˆ¶
- [ ] æŒæ¡ Data é…ç½®é¡¹
- [ ] æŒæ¡ Actor é…ç½®é¡¹
- [ ] æŒæ¡ Rollout é…ç½®é¡¹
- [ ] èƒ½å¤Ÿé€šè¿‡å‘½ä»¤è¡Œè¦†ç›–é…ç½®
- [ ] çŸ¥é“å¦‚ä½•åˆ‡æ¢ç®—æ³•ï¼ˆPPO/GRPO/RLOOï¼‰

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

âœ… ç‹¬ç«‹æ­å»º verl è®­ç»ƒç¯å¢ƒ
âœ… ç†è§£å®Œæ•´çš„è®­ç»ƒæµç¨‹
âœ… æŒæ¡ RayPPOTrainer çš„å·¥ä½œåŸç†
âœ… ç†Ÿç»ƒä½¿ç”¨ Hydra é…ç½®ç³»ç»Ÿ
âœ… èƒ½å¤Ÿè°ƒä¼˜è®­ç»ƒå‚æ•°
âœ… è°ƒè¯•è®­ç»ƒé—®é¢˜

---

## ğŸ’¡ é‡ç‚¹å†…å®¹

### è®­ç»ƒæµç¨‹çš„ 7 ä¸ªé˜¶æ®µï¼ˆé‡è¦ï¼ï¼‰

```
1. Rolloutï¼ˆç”Ÿæˆï¼‰     â†’ è°ƒç”¨ vLLM/SGLang ç”Ÿæˆå“åº”
2. Rewardï¼ˆå¥–åŠ±ï¼‰      â†’ è®¡ç®—æ¯ä¸ªå“åº”çš„åˆ†æ•°
3. Refï¼ˆå‚è€ƒï¼‰         â†’ è®¡ç®—å‚è€ƒæ¨¡å‹çš„ log prob
4. Valueï¼ˆä»·å€¼ï¼‰       â†’ Critic é¢„æµ‹ valueï¼ˆPPOï¼‰
5. Advantageï¼ˆä¼˜åŠ¿ï¼‰   â†’ è®¡ç®—ä¼˜åŠ¿å€¼ï¼ˆæ ¸å¿ƒï¼ï¼‰
6. Actor Updateï¼ˆæ›´æ–°ï¼‰â†’ æ›´æ–°ç­–ç•¥æ¨¡å‹
7. Critic Updateï¼ˆæ›´æ–°ï¼‰â†’ æ›´æ–°ä»·å€¼å‡½æ•°ï¼ˆPPOï¼‰
```

### é…ç½®ä¼˜å…ˆçº§ï¼ˆé‡è¦ï¼ï¼‰

```
defaults ä¸­çš„é…ç½®
    â†“
å½“å‰æ–‡ä»¶ï¼ˆ_self_ï¼‰
    â†“
å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
```

### Batch Size è®¡ç®—ï¼ˆé‡è¦ï¼ï¼‰

```yaml
train_batch_size: 256      # 256 ä¸ª prompts
rollout.n: 4               # æ¯ä¸ª prompt ç”Ÿæˆ 4 ä¸ªå“åº”
â†’ æ€»å“åº”æ•° = 256 * 4 = 1024

ppo_mini_batch_size: 64    # åˆ†æˆ 16 ä¸ª mini-batch
â†’ æ¯ä¸ª mini-batch: 64 ä¸ªå“åº”
â†’ æ›´æ–°æ¬¡æ•°: 16 æ¬¡
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**ç“¶é¢ˆé€šå¸¸åœ¨ Rollout é˜¶æ®µï¼ˆvLLM ç”Ÿæˆï¼‰**

è§£å†³æ–¹æ³•ï¼š
- å‡å° `data.max_response_length`
- å¢åŠ  GPU æ•°é‡
- ä½¿ç”¨æ›´å¿«çš„æ¨ç†å¼•æ“ï¼ˆSGLangï¼‰

### Q2: OOM æ€ä¹ˆåŠï¼Ÿ

```yaml
# æ–¹æ¡ˆ 1: å‡å° micro batch
ppo_micro_batch_size_per_gpu: 2

# æ–¹æ¡ˆ 2: å‡å° rollout æ˜¾å­˜
rollout.gpu_memory_utilization: 0.3

# æ–¹æ¡ˆ 3: ä½¿ç”¨ gradient checkpointing
model.enable_gradient_checkpointing: true
```

### Q3: å¦‚ä½•çŸ¥é“è®­ç»ƒæ˜¯å¦æ­£å¸¸ï¼Ÿ

å…³é”®æŒ‡æ ‡ï¼š
- `reward/mean`: åº”è¯¥æŒç»­ä¸Šå‡
- `kl/mean`: ä¿æŒåœ¨ 0.1-5 ä¹‹é—´
- `actor/loss`: é€æ­¥ä¸‹é™
- `accuracy`: åœ¨ GSM8K ä¸Šåº”è¯¥æå‡

### Q4: å¦‚ä½•ä¿®æ”¹é…ç½®ï¼Ÿ

```bash
# å‘½ä»¤è¡Œè¦†ç›–ï¼ˆæ¨èï¼‰
python3 -m verl.trainer.main_ppo \
    actor_rollout_ref.actor.optim.lr=5e-7

# åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶
# å¤åˆ¶ verl/trainer/config/ppo_trainer.yaml
# ä¿®æ”¹åä½¿ç”¨ --config-path æŒ‡å®š
```

---

## ğŸ”— ç›¸å…³èµ„æº

### æœ¬åœ°æ–‡ä»¶
- é¡¹ç›®æ¦‚è§ˆ: `../../CLAUDE.md`
- å®Œæ•´å­¦ä¹ è·¯çº¿: `../../LEARNING_GUIDE.md`
- ç¬¬äºŒéƒ¨åˆ†: `../02_æ•°æ®å‡†å¤‡/`

### å®˜æ–¹æ–‡æ¡£
- [Quickstart](https://verl.readthedocs.io/en/latest/start/quickstart.html)
- [HybridFlow](https://verl.readthedocs.io/en/latest/hybrid_flow.html)
- [Config Explanation](https://verl.readthedocs.io/en/latest/examples/config.html)

### ä»£ç ä½ç½®
- è®­ç»ƒå…¥å£: `verl/trainer/main_ppo.py`
- è®­ç»ƒä¸»å¾ªç¯: `verl/trainer/ppo/ray_trainer.py`
- æ ¸å¿ƒç®—æ³•: `verl/trainer/ppo/core_algos.py`
- é…ç½®æ–‡ä»¶: `verl/trainer/config/`

---

## â­ï¸ ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« åï¼Œç»§ç»­å­¦ä¹ ï¼š
- **02 - æ•°æ®å‡†å¤‡**: æ·±å…¥ç†è§£æ•°æ®æ ¼å¼å’Œ Reward ç³»ç»Ÿ
- **03 - RL ç®—æ³•**: æ·±å…¥ç†è§£ GRPOã€PPO ç­‰ç®—æ³•
- **04 - Reward è®¾è®¡**: å®ç°è‡ªå®šä¹‰ Reward å‡½æ•°
- **05 - Agent RL**: Agent å¤šè½®å¯¹è¯è®­ç»ƒ

---

*åˆ›å»ºæ—¶é—´: 2026-01-25*
*é¢„è®¡å®Œæˆæ—¶é—´: 3 å¤©*
